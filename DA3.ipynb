{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1>Tanish Chhabra<br>\n",
    "101916038<br>\n",
    "CS10</h1>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cudf\n",
    "import cupy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h2>Q.1</h2>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**<h3>Using numpy, pandas and sklearn</h3>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCAwY95YhRjh",
    "outputId": "6fbb11e3-ebd4-4b80-9118-26b79974735a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1\n",
      "Beta:  [1231872.07704612  229923.70318635  164052.98579011  120923.57426579\n",
      "    3533.77470973  151855.58542488]\n",
      "SSE: 10087104444118.805 ,MSE: 10087104444.118805 ,RMSE: 100434.57793070475\n",
      "R2 score: 0.9175899480765108\n",
      "\n",
      "\n",
      "Iteration:  2\n",
      "Beta:  [1232586.40453402  228365.32287054  165201.14881927  122539.46855211\n",
      "    1697.03433458  150055.81710562]\n",
      "SSE: 10728109153419.246 ,MSE: 10728109153.419247 ,RMSE: 103576.58593243574\n",
      "R2 score: 0.9203015496401128\n",
      "\n",
      "\n",
      "Iteration:  3\n",
      "Beta:  [1231448.09063371  230730.20810582  163554.55706976  121669.08713233\n",
      "    2620.25215054  150923.12489298]\n",
      "SSE: 9861616305461.945 ,MSE: 9861616305.461945 ,RMSE: 99305.67106395256\n",
      "R2 score: 0.9152429915320014\n",
      "\n",
      "\n",
      "Iteration:  4\n",
      "Beta:  [1.23144707e+06 2.29921558e+05 1.64523054e+05 1.19737507e+05\n",
      " 1.12425659e+03 1.51317802e+05]\n",
      "SSE: 10176314743926.252 ,MSE: 10176314743.926252 ,RMSE: 100877.72174234633\n",
      "R2 score: 0.9208503836977653\n",
      "\n",
      "\n",
      "Iteration:  5\n",
      "Beta:  [1233028.38536436  230778.59921985  163755.13607252  121885.1351222\n",
      "    1247.01304382  150084.29759618]\n",
      "SSE: 10415367206826.3 ,MSE: 10415367206.826302 ,RMSE: 102055.70639031558\n",
      "R2 score: 0.9138111758717498\n",
      "\n",
      "\n",
      "Max R2 score: 0.9208503836977653\n",
      "Corresponding Beta matrix: [1.23144707e+06 2.29921558e+05 1.64523054e+05 1.19737507e+05\n",
      " 1.12425659e+03 1.51317802e+05] \n",
      "\n",
      "SSE: 15101749043647.4 \n",
      "MSE: 10067832695.764935 \n",
      "RMSE: 100338.59026199707\n",
      "\n",
      "R2 score: 0.91468684821474 \n",
      "\n",
      "CPU times: user 21.2 ms, sys: 3.07 ms, total: 24.2 ms\n",
      "Wall time: 22.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Importing Dataset\n",
    "df = pd.read_csv('../datasets/USA_Housing (1).csv')\n",
    "\n",
    "#Dividing dataset into X(input variables) and Y(output variables)\n",
    "X = df.iloc[:,:5]\n",
    "Y = df.iloc[:,5]\n",
    "\n",
    "#Scaling Input variables\n",
    "ss = StandardScaler()\n",
    "X_scaled = ss.fit_transform(X)\n",
    "x = np.insert(X_scaled,0,1,axis=1)\n",
    "\n",
    "#Dividing input and output features into 5 folds\n",
    "beta = []\n",
    "r2 = -1\n",
    "\n",
    "no_of_folds = 5\n",
    "n = len(X)\n",
    "one_fold = n//no_of_folds\n",
    "index = np.arange(0,n,1)\n",
    "\n",
    "for i in range(no_of_folds):\n",
    "    print(\"Iteration: \",i+1)\n",
    "    \n",
    "    test_index = np.arange(one_fold*i,one_fold*(i+1),1)\n",
    "    train_index = np.delete(index,test_index)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = x[train_index], x[test_index], Y[train_index], Y[test_index]\n",
    "\n",
    "    a = x_train.T.dot(x_train)\n",
    "    b = np.linalg.inv(a)\n",
    "    c = b.dot(x_train.T)\n",
    "    beta_temp = c.dot(y_train)\n",
    "    print(\"Beta: \",beta_temp)\n",
    "\n",
    "    #Predicting Y\n",
    "    y_predicted = x_test.dot(beta_temp)\n",
    "\n",
    "    #Calculating error, sse, mse, rmse\n",
    "    error = y_predicted - y_test\n",
    "    sse = np.sum(error**2)\n",
    "    mse = sse/len(y_test)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"SSE:\",sse,\",MSE:\",mse,\",RMSE:\",rmse)\n",
    "\n",
    "    #Calculating R2\n",
    "    y_mean = np.mean(y_test)\n",
    "    total_variance = np.sum((y_test-y_mean)**2)\n",
    "    r2_temp = 1-sse/total_variance  \n",
    "    print(\"R2 score:\",r2_temp)\n",
    "\n",
    "    #Optimised R2\n",
    "    if r2_temp >= r2:\n",
    "        r2 = r2_temp\n",
    "        beta = beta_temp\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Max R2 score:\",r2)\n",
    "print(\"Corresponding Beta matrix:\",beta,\"\\n\")\n",
    "\n",
    "#Testing 30% data with optimal value of beta\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,Y,test_size=0.30,random_state=42)\n",
    "\n",
    "#Predicting Y\n",
    "y_predicted = x_test.dot(beta)\n",
    "y_predicted\n",
    "\n",
    "#Calculating error,sse,mse,rmse and R2 score\n",
    "error = y_predicted - y_test\n",
    "sse = np.sum(error**2)\n",
    "mse = sse/len(y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"SSE:\",sse,\"\\nMSE:\",mse,\"\\nRMSE:\",rmse)\n",
    "print()\n",
    "\n",
    "y_mean = np.mean(y_test)\n",
    "total_variance = np.sum((y_test-y_mean)**2)\n",
    "r2_temp = 1-sse/total_variance  \n",
    "print(\"R2 score:\",r2_temp,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**<h3>Using CuDF, CuPy and CuML</h3>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.preprocessing import StandardScaler\n",
    "from cuml.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCAwY95YhRjh",
    "outputId": "6fbb11e3-ebd4-4b80-9118-26b79974735a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 6 columns):\n",
      " #   Column                        Non-Null Count  Dtype\n",
      "---  ------                        --------------  -----\n",
      " 0   Avg. Area Income              5000 non-null   float64\n",
      " 1   Avg. Area House Age           5000 non-null   float64\n",
      " 2   Avg. Area Number of Rooms     5000 non-null   float64\n",
      " 3   Avg. Area Number of Bedrooms  5000 non-null   float64\n",
      " 4   Area Population               5000 non-null   float64\n",
      " 5   Price                         5000 non-null   float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 234.4 KB\n",
      "Iteration:  1\n",
      "Beta:  [1231872.07704612  229923.70318635  164052.98579011  120923.57426579\n",
      "    3533.77470973  151855.58542488]\n",
      "SSE: 10087104444118.816 ,MSE: 10087104444.118816 ,RMSE: 100434.5779307048\n",
      "R2 score: 0.9175899480765107\n",
      "\n",
      "\n",
      "Iteration:  2\n",
      "Beta:  [1232586.40453402  228365.32287054  165201.14881927  122539.46855211\n",
      "    1697.03433458  150055.81710562]\n",
      "SSE: 10728109153419.22 ,MSE: 10728109153.41922 ,RMSE: 103576.58593243561\n",
      "R2 score: 0.920301549640113\n",
      "\n",
      "\n",
      "Iteration:  3\n",
      "Beta:  [1231448.09063371  230730.20810582  163554.55706976  121669.08713233\n",
      "    2620.25215054  150923.12489298]\n",
      "SSE: 9861616305461.941 ,MSE: 9861616305.46194 ,RMSE: 99305.67106395254\n",
      "R2 score: 0.9152429915320014\n",
      "\n",
      "\n",
      "Iteration:  4\n",
      "Beta:  [1.23144707e+06 2.29921558e+05 1.64523054e+05 1.19737507e+05\n",
      " 1.12425659e+03 1.51317802e+05]\n",
      "SSE: 10176314743926.219 ,MSE: 10176314743.926218 ,RMSE: 100877.72174234616\n",
      "R2 score: 0.9208503836977656\n",
      "\n",
      "\n",
      "Iteration:  5\n",
      "Beta:  [1233028.38536436  230778.59921985  163755.13607252  121885.1351222\n",
      "    1247.01304382  150084.29759618]\n",
      "SSE: 10415367206826.336 ,MSE: 10415367206.826336 ,RMSE: 102055.70639031575\n",
      "R2 score: 0.9138111758717495\n",
      "\n",
      "\n",
      "Max R2 score: 0.9208503836977656\n",
      "Corresponding Beta matrix: [1.23144707e+06 2.29921558e+05 1.64523054e+05 1.19737507e+05\n",
      " 1.12425659e+03 1.51317802e+05] \n",
      "\n",
      "SSE: 14895112667431.854 \n",
      "MSE: 9930075111.621235 \n",
      "RMSE: 99649.76222561314\n",
      "R2 score: 0.9217682430219668 \n",
      "\n",
      "CPU times: user 36.5 ms, sys: 4.27 ms, total: 40.8 ms\n",
      "Wall time: 38.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Importing Dataset\n",
    "df = cudf.read_csv('../datasets/USA_Housing (1).csv')\n",
    "df.info()\n",
    "\n",
    "#Dividing dataset into X(input variables) and Y(output variables)\n",
    "X = df.iloc[:,:5]\n",
    "Y = df.iloc[:,5]\n",
    "Y = cupy.asarray(Y)\n",
    "\n",
    "#Scaling Input variables\n",
    "ss = StandardScaler()\n",
    "X_scaled = ss.fit_transform(X)\n",
    "X_scaled.insert(0,-1,1.0)\n",
    "X_scaled = cupy.fromDlpack(X_scaled.to_dlpack())\n",
    "x = X_scaled\n",
    "\n",
    "#Dividing input and output features into 5 folds\n",
    "beta = []\n",
    "r2 = -1\n",
    "\n",
    "no_of_folds = 5\n",
    "n = len(X)\n",
    "one_fold = n//no_of_folds\n",
    "index = np.arange(0,n,1)\n",
    "\n",
    "for i in range(no_of_folds):\n",
    "    print(\"Iteration: \",i+1)\n",
    "    \n",
    "    test_index = np.arange(one_fold*i,one_fold*(i+1),1)\n",
    "    train_index = np.delete(index,test_index)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = x[train_index], x[test_index], Y[train_index], Y[test_index]\n",
    "\n",
    "    a = x_train.T.dot(x_train)\n",
    "    b = cupy.linalg.inv(a)\n",
    "    c = b.dot(x_train.T)\n",
    "    beta_temp = c.dot(y_train)\n",
    "    print(\"Beta: \",beta_temp)\n",
    "\n",
    "    #Predicting Y\n",
    "    y_predicted = x_test.dot(beta_temp)\n",
    "\n",
    "    #Calculating error, sse, mse, rmse\n",
    "    error = y_predicted - y_test\n",
    "    sse = cupy.sum(error**2)\n",
    "    mse = sse/len(y_test)\n",
    "    rmse = cupy.sqrt(mse)\n",
    "    print(\"SSE:\",sse,\",MSE:\",mse,\",RMSE:\",rmse)\n",
    "\n",
    "    #Calculating R2\n",
    "    y_mean = cupy.mean(y_test)\n",
    "    total_variance = cupy.sum((y_test-y_mean)**2)\n",
    "    r2_temp = 1-sse/total_variance  \n",
    "    print(\"R2 score:\",r2_temp)\n",
    "\n",
    "    #Optimised R2\n",
    "    if r2_temp >= r2:\n",
    "        r2 = r2_temp\n",
    "        beta = beta_temp\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Max R2 score:\",r2)\n",
    "print(\"Corresponding Beta matrix:\",beta,\"\\n\")\n",
    "\n",
    "#Testing 30% data with optimal value of beta\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,Y,test_size=0.30,random_state=42)\n",
    "\n",
    "#Predicting Y\n",
    "y_predicted = x_test.dot(beta)\n",
    "y_predicted\n",
    "\n",
    "#Calculating error,sse,mse,rmse and R2 score\n",
    "error = y_predicted - y_test\n",
    "sse = np.sum(error**2)\n",
    "mse = sse/len(y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"SSE:\",sse,\"\\nMSE:\",mse,\"\\nRMSE:\",rmse)\n",
    "\n",
    "y_mean = np.mean(y_test)\n",
    "total_variance = np.sum((y_test-y_mean)**2)\n",
    "r2_temp = 1-sse/total_variance  \n",
    "print(\"R2 score:\",r2_temp,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Total time using GPU accelerated code - 40.8ms<br>\n",
    "Total time without using GPU accelerated code - 24.2ms</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h2>Q.2</h2>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h3>Using sklearn</h3>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9146818498916267 \n",
      "\n",
      "CPU times: user 11.9 ms, sys: 0 ns, total: 11.9 ms\n",
      "Wall time: 11.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('../datasets/USA_Housing (1).csv')\n",
    "\n",
    "X = df.iloc[:,:5]\n",
    "Y = df.iloc[:,5]\n",
    "\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_scaled = ss.fit_transform(X)\n",
    "x = np.insert(X_scaled,0,1,axis=1)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,Y,test_size=0.30,random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "predicted = model.predict(x_test)\n",
    "\n",
    "print(metrics.r2_score(y_test, predicted),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**<h3>Using cuml</h3>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.preprocessing import StandardScaler\n",
    "from cuml.model_selection import train_test_split\n",
    "from cuml.linear_model import LinearRegression\n",
    "from cuml import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9143798851361878 \n",
      "\n",
      "CPU times: user 33 ms, sys: 3.61 ms, total: 36.6 ms\n",
      "Wall time: 35.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = cudf.read_csv('../datasets/USA_Housing (1).csv')\n",
    "\n",
    "X = df.iloc[:,:5]\n",
    "Y = df.iloc[:,5]\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_scaled = ss.fit_transform(X)\n",
    "X_scaled.insert(0,-1,1.0)\n",
    "#X_scaled = cupy.fromDlpack(X_scaled.to_dlpack())\n",
    "x = X_scaled\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,Y,test_size=0.30,random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "predicted = model.predict(x_test)\n",
    "\n",
    "print(metrics.r2_score(y_test, predicted),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Total time using GPU accelerated code - 36.6ms<br>\n",
    "Total time without using GPU accelerated code - 11.9ms</h3>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DA_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
